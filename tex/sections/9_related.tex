\section{Related Work}
\label{sec:related}

\paragraph{Discrete-only probabilistic languages.}  
Several recent systems achieve \emph{exact inference} by restricting models to finite, discrete random variables. \emph{Roulette} extends Racket with first-class support for finitely-supported distributions and leverages symbolic evaluation to compile queries into weighted model-counting problems, enabling scalable exact conditioning on complex programs~\cite{Moy2025Roulette}. \emph{Dice} follows a similar philosophy in an OCaml DSL, compiling discrete programs to weighted model counting to perform exact Bayesian updates even on thousands of Boolean and finite-categorical variables~\cite{Holtzen2020Dice}. Earlier work in probabilistic logic programming, most prominently \emph{ProbLog}, annotates Prolog facts with probabilities and reduces inference to weighted Boolean formulas that can likewise be solved exactly~\cite{DeRaedt2007ProbLog}. These languages demonstrate the power of exact reasoning, but by construction they \emph{cannot express continuous random quantities}; consequently they offer no built-in path for analysing models that naturally mix real-valued and discrete structure.  

\paragraph{Symbolic treatment of mixed models.}  
\emph{SPPL} occupies an intermediate point on the design spectrum. By enforcing syntactic restrictions that guarantee every program can be translated into a finite \emph{sum-product expression}, SPPL supports models with both discrete and continuous components while still admitting \emph{symbolic} exact inference~\cite{Saad2021SPPL}. Rather than discretising the continuous parts, SPPL derives closed-form integrals when possible; exactness is retained for a narrow class of models. There is no mechanism for turning the remaining continuous structure into a discrete program that could reuse the powerful inference back-ends of Dice, Roulette, or ProbLog.

\paragraph{Continuous and hybrid PPLs with approximate inference.}  
The majority of widely-used PPLs treat \emph{continuous} distributions as first-class and rely on approximate inference. Systems such as \emph{Stan} (C++), \emph{PyMC} (Python), \emph{Pyro} (Python on PyTorch), \emph{TensorFlow Probability} and its precursor \emph{Edward} expose rich continuous distributions and obtain posteriors with Hamiltonian Monte Carlo, variational inference, or sequential Monte Carlo~\cite{Carpenter2017Stan,Salvatier2016PyMC3,Bingham2019Pyro,Dillon2017TFP,Tran2016Edward}. These frameworks deliver high accuracy for differentiable densities but can struggle with discrete latent structure or discontinuities that arise after na√Øve discretisation. Crucially, none of them offers an automated pathway to convert continuous sub-expressions into discrete replacements that would make exact inference feasible.

\paragraph{Universal languages supporting both regimes.}  
Universal or ``hybrid'' languages aim for expressiveness by embedding probabilistic primitives into general-purpose hosts. \emph{Anglican} (Clojure), \emph{WebPPL} (JavaScript), \emph{Figaro} (Scala) and \emph{Infer.NET} (C\#) permit arbitrary mixtures of discrete and continuous variables with inference based on importance sampling, Gibbs, expectation propagation, or lightweight MCMC~\cite{Tolpin2016Anglican,Goodman2014WebPPL,Pfeffer2009Figaro,Minka2018InferNET}. More recently, Julia-based systems such as \emph{Turing.jl} and \emph{Gen.jl} expose programmable inference interfaces, while \emph{Bean Machine} offers a declarative syntax atop PyTorch~\cite{Ge2018Turing,CusumanoTowner2019Gen,Tehrani2020BeanMachine}. Classic languages like \emph{Church} pioneered the ``evaluation-as-sampling'' view that underlies many of these systems~\cite{Goodman2008Church}. Discretization transformations are left entirely to the user and are not integrated with the inference engine.

\paragraph{Probabilistic program abstraction.}
The work of \cite{Holtzen2018Abstraction} is perhaps most similar to our own in its aim to simplify probabilistic programs for easier inference.
They use ideas from abstract interpretation to transform a program with continuous and discrete random variables into a finite Boolean program based on user-provided predicates.
This *predicate abstraction* is proven to be \emph{distributionally sound}, meaning that for any query expressed in the predicate vocabulary, the abstract program gives the same probability as the concrete one.
Their method works by taking a set of predicates and automatically adding *completion* predicates to create a tight abstraction.
Inference then proceeds by querying the abstract Boolean program and using a concrete inference engine for sub-queries.
While this approach is powerful, it has several limitations.
The selection of predicates is left to the user, and a poor choice can lead to a coarse abstraction or a combinatorial explosion in the number of completion predicates.
Furthermore, the full automation of their technique is limited to loop-free programs.
Our work, in contrast, does not require user-provided predicates. Instead, \Slice{} automatically infers the necessary "cut points" from the program text using a novel type system, and our approach supports features like recursion.

\paragraph{Logical relations for probabilistic programs.}
Our soundness proof builds on the rich literature of logical relations for probabilistic programs.
Early foundational work by Kozen~\cite{Kozen1981Semantics} and Jones \& Plotkin~\cite{Jones1989Probabilistic} established denotational and operational models for probabilistic languages, with later work by Ramsey \& Pfeffer~\cite{Ramsey2002Stochastic} introducing monadic structures for probability and Dal Lago \& Zorzi~\cite{DiLago2012Probabilistic} developing operational semantics for probabilistic lambda calculus.
Building on these foundations, logical relations have been extended to prove contextual equivalences in increasingly expressive probabilistic languages.
Johann et al.~\cite{Johann2010Generic} introduced a generic operational logical relations framework that handles probabilistic choice alongside other effects.
Bizjak \& Birkedal~\cite{Bizjak2015Step} constructed the first step-indexed logical relation for higher-order probabilistic languages with impredicative polymorphism and recursive types, proving soundness and completeness for contextual preorder.
Recent work has pushed these techniques further: Wand et al.~\cite{Wand2018Contextual} addressed languages with continuous distributions and general recursion, Zhang \& Amin~\cite{Zhang2022Reasoning} handled nested probabilistic queries, and Aguirre \& Birkedal~\cite{Aguirre2023Step} combined probabilistic and nondeterministic choice using countable ordinal indexing.
In the realm of program logics, relational probabilistic Hoare logics (pRHL) have been developed for verifying security and privacy properties~\cite{Barthe2009Formal,Barthe2012Privacy}, with recent work on quantitative extensions achieving completeness for almost-surely terminating programs~\cite{Avanzini2025Quantitative}.
These techniques have been implemented in various verification tools and extended to new domains, including EasyCrypt for cryptographic proofs~\cite{Barthe2011Computer}, CryptHOL for game-based proofs in Isabelle/HOL~\cite{Basin2020CryptHOL}, advanced coupling-based rules for differential privacy~\cite{Barthe2016Proving,Barthe2016Advanced}, synthesis of coupling proofs~\cite{Albarghouthi2018Synthesizing}, and even quantum programs~\cite{Barthe2020Quantum}.
Our work adapts these logical relation techniques to prove soundness of discretization, establishing that our transformation preserves program semantics.

\paragraph{Positioning of our work.}  
Our contribution lies precisely at the intersection left open by the above lines of research. We propose a \emph{language-level transformation} that automatically discretises continuous sub-programs while preserving the semantics required for exact Bayesian reasoning in the discrete fragment. When discretization successfully translates all continuous distributions, we can translate the program into the finite domain accepted by Dice (or Roulette, or ProbLog), and inherit their fast exact inference without sacrificing the modelling convenience of continuous distributions. 
Empirically, our approach of discretizing programs and running them through Dice's inference engine achieves significantly faster runtimes compared to SPPL's symbolic methods, while maintaining exactness. Unlike continuous PPLs that settle for stochastic approximations, our approach bridges the gap between expressive modelling and fast exact computation. Partial discretization is also possible, and could be used to speed up inference without sacrificing expressiveness.

\medskip  
In summary, existing discrete PPLs excel at exactness but lack continuous support, symbolic languages like SPPL require restrictive structure and are slower than model counting approaches, and continuous or hybrid frameworks favour approximate inference. To our knowledge none of these systems automates the conversion of continuous programs into a discrete representation amenable to exact inference; our work addresses precisely that missing piece.

\paragraph{Future work.}
In the future, we would like to extend our work to symbolically integrate tractable combinations of continous distributions beyond the cumulative distribution function.
We would also like to improve mixed continuous-discrete inference by partial discretization, summing out the discrete variables using weighted model counting techniques, and running the remaining continuous inference using standard continuous inference techniques.