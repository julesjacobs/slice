\section{Soundness Proof}\label{sec:soundness}

This section establishes the soundness of our discretization transformation. We proceed in three steps: first, we define a nondeterministic small-step semantics for the base language; second, we extend this to a probabilistic semantics that tracks distributions; and third, we prove that discretization preserves the probabilistic semantics.

\subsection{Nondeterministic Small-Step Semantics}

We begin by defining a small-step operational semantics for \Slice{} that treats probabilistic sampling nondeterministically. This semantics captures the possible values that expressions can take without tracking their probabilities.

\subsubsection{Values}

First, we define the set of values that expressions can evaluate to:
\begin{align*}
v ::= &\; c                                  & \text{float constant} \\
    | &\; \text{true} \mid \text{false}      & \text{boolean value} \\
    | &\; \finconst{k}{n}                    & \text{finite type value} \\
    | &\; i                                  & \text{integer value} \\
    | &\; ()                                 & \text{unit value} \\
    | &\; (v_1, v_2)                         & \text{pair value} \\
    | &\; \funkw \; x \; \rightarrow \; e    & \text{function closure} \\
    | &\; \text{nil}                         & \text{empty list} \\
    | &\; v_1 :: v_2                         & \text{list cons value} \\
    | &\; \ell                               & \text{location (for references)}
\end{align*}

\subsubsection{Evaluation Contexts}

We use evaluation contexts to specify the order of evaluation:
\begin{align*}
E ::= &\; [\cdot] \\
    | &\; \letkw \; x = E \; \inkw \; e \\
    | &\; E < e \mid v < E \\
    | &\; E \leq e \mid v \leq E \\
    | &\; E \finlt{n} e \mid v \finlt{n} E \\
    | &\; E \finleq{n} e \mid v \finleq{n} E \\
    | &\; E \logand e \mid v \logand E \\
    | &\; E \logor e \mid v \logor E \\
    | &\; \text{not}\; E \\
    | &\; \ifkw \; E \; \thenkw \; e_1 \; \elsekw \; e_2 \\
    | &\; (E, e) \mid (v, E) \\
    | &\; \fstkw \; E \mid \sndkw \; E \\
    | &\; E \; e \mid v \; E \\
    | &\; \text{observe}\; E \\
    | &\; E; e \\
    | &\; E :: e \mid v :: E \\
    | &\; \text{match}\; E \; \text{with}\; \ldots \\
    | &\; \text{ref}\; E \\
    | &\; !E \\
    | &\; E := e \mid v := E
\end{align*}

\subsubsection{Small-Step Relation}

We define the small-step relation $e \rightarrow \mathcal{P}(e')$ that maps an expression to a set of possible next expressions. For deterministic constructs, this set is a singleton; for probabilistic sampling, it contains all possible values in the distribution's support.

\paragraph{Basic Rules}

\begin{mathpar}
\inferrule[\textsc{Let}]
{\ }
{\letkw \; x = v \; \inkw \; e \rightarrow \{e[v/x]\}}

\inferrule[\textsc{IfTrue}]
{\ }
{\ifkw \; \text{true} \; \thenkw \; e_1 \; \elsekw \; e_2 \rightarrow \{e_1\}}

\inferrule[\textsc{IfFalse}]
{\ }
{\ifkw \; \text{false} \; \thenkw \; e_1 \; \elsekw \; e_2 \rightarrow \{e_2\}}

\inferrule[\textsc{Fst}]
{\ }
{\fstkw \; (v_1, v_2) \rightarrow \{v_1\}}

\inferrule[\textsc{Snd}]
{\ }
{\sndkw \; (v_1, v_2) \rightarrow \{v_2\}}

\inferrule[\textsc{App}]
{\ }
{(\funkw \; x \; \rightarrow \; e) \; v \rightarrow \{e[v/x]\}}
\end{mathpar}

\paragraph{Comparison Rules}

\begin{mathpar}
\inferrule[\textsc{LessTrue}]
{c_1 < c_2}
{c_1 < c_2 \rightarrow \{\text{true}\}}

\inferrule[\textsc{LessFalse}]
{c_1 \geq c_2}
{c_1 < c_2 \rightarrow \{\text{false}\}}

\inferrule[\textsc{LeqTrue}]
{i_1 \leq i_2}
{i_1 \leq i_2 \rightarrow \{\text{true}\}}

\inferrule[\textsc{LeqFalse}]
{i_1 > i_2}
{i_1 \leq i_2 \rightarrow \{\text{false}\}}
\end{mathpar}

\paragraph{Boolean Operations}

\begin{mathpar}
\inferrule[\textsc{AndTrue}]
{\ }
{\text{true} \logand e \rightarrow \{e\}}

\inferrule[\textsc{AndFalse}]
{\ }
{\text{false} \logand e \rightarrow \{\text{false}\}}

\inferrule[\textsc{OrTrue}]
{\ }
{\text{true} \logor e \rightarrow \{\text{true}\}}

\inferrule[\textsc{OrFalse}]
{\ }
{\text{false} \logor e \rightarrow \{e\}}

\inferrule[\textsc{NotTrue}]
{\ }
{\text{not}\; \text{true} \rightarrow \{\text{false}\}}

\inferrule[\textsc{NotFalse}]
{\ }
{\text{not}\; \text{false} \rightarrow \{\text{true}\}}
\end{mathpar}

\paragraph{List Operations}

\begin{mathpar}
\inferrule[\textsc{MatchNil}]
{\ }
{\text{match}\; \text{nil} \; \text{with}\; \text{nil} \rightarrow e_1 \mid h :: t \rightarrow e_2 \; \text{end} \rightarrow \{e_1\}}

\inferrule[\textsc{MatchCons}]
{\ }
{\text{match}\; v_1 :: v_2 \; \text{with}\; \text{nil} \rightarrow e_1 \mid h :: t \rightarrow e_2 \; \text{end} \rightarrow \{e_2[v_1/h, v_2/t]\}}
\end{mathpar}

\paragraph{Probabilistic Sampling (Nondeterministic)}

For continuous distributions, the small-step relation returns the set of all possible values in the distribution's support:

\begin{mathpar}
\inferrule[\textsc{Uniform}]
{v_1, v_2 \text{ are float values} \\ v_1 < v_2}
{\uniform(v_1, v_2) \rightarrow \{c \mid v_1 \leq c < v_2\}}

\inferrule[\textsc{Gaussian}]
{\mu, \sigma \text{ are float values} \\ \sigma > 0}
{\gaussian(\mu, \sigma) \rightarrow \{c \mid c \in \mathbb{R}\}}

\inferrule[\textsc{Exponential}]
{\lambda \text{ is a float value} \\ \lambda > 0}
{\exponential(\lambda) \rightarrow \{c \mid c \geq 0\}}

\inferrule[\textsc{Beta}]
{\alpha, \beta \text{ are float values} \\ \alpha > 0 \\ \beta > 0}
{\betafn(\alpha, \beta) \rightarrow \{c \mid 0 \leq c \leq 1\}}

\inferrule[\textsc{Discrete}]
{p_0, \ldots, p_n \text{ are probabilities}}
{\discrete(p_0, \ldots, p_n) \rightarrow \{0, 1, \ldots, n\}}
\end{mathpar}

\paragraph{Observations}

\begin{mathpar}
\inferrule[\textsc{ObserveTrue}]
{\ }
{\text{observe}\; \text{true} \rightarrow \{()\}}

\inferrule[\textsc{ObserveFalse}]
{\ }
{\text{observe}\; \text{false} \rightarrow \emptyset}
\end{mathpar}

Note that observing a false condition results in an empty set, representing program termination without producing a value.

\paragraph{References and State}

For references, we extend the semantics with a store $\sigma$ that maps locations to values. The relation becomes $\langle e, \sigma \rangle \rightarrow \mathcal{P}(\langle e', \sigma' \rangle)$:

\begin{mathpar}
\inferrule[\textsc{Ref}]
{\ell \text{ is a fresh location}}
{\langle \text{ref}\; v, \sigma \rangle \rightarrow \{\langle \ell, \sigma[\ell \mapsto v] \rangle\}}

\inferrule[\textsc{Deref}]
{\sigma(\ell) = v}
{\langle !\ell, \sigma \rangle \rightarrow \{\langle v, \sigma \rangle\}}

\inferrule[\textsc{Assign}]
{\ }
{\langle \ell := v, \sigma \rangle \rightarrow \{\langle (), \sigma[\ell \mapsto v] \rangle\}}
\end{mathpar}

\paragraph{Context Rule}

\begin{mathpar}
\inferrule[\textsc{Context}]
{e \rightarrow S}
{E[e] \rightarrow \{E[e'] \mid e' \in S\}}
\end{mathpar}

This nondeterministic semantics captures all possible execution paths of a probabilistic program without tracking the probability of each path. In the next subsection, we will extend this to a probabilistic semantics that properly tracks distributions.

\subsection{Probabilistic Small-Step Semantics}

We now define a probabilistic semantics that tracks the distribution over expressions. Define
%
\[
	\extexprs = \exprs \cup  \{ \error \} \cup \{ \obsfail \}~,
\]
%
and call them \emph{extended expressions}.
%
%where $\error$ indicates a type error and $\obsfail$ denotes observation failure.
The semantic function $\sem{\cdot} \colon \exprs \rightarrow \distexprs$ maps expressions to distributions over expressions, where $\dist{X}$ denotes the space of probability distributions over $X$.

We assume the existence of the Giry monad structure on $\mathcal{D}$, which provides:
\begin{itemize}
    \item $\monunit \colon X \rightarrow \dist{X}$ (also written as $\delta_x$ for the Dirac distribution at $x$)
    \item $\monbind \colon \dist{X} \times (X \to \dist{Y}) \rightarrow \dist{Y}$ (monadic bind)
\end{itemize}

\subsubsection{Deterministic Constructs}

For deterministic constructs, the semantics returns a Dirac distribution:

\paragraph{Values and Basic Operations}
\begin{align*}
\sem{\val} &= \delta_\val \quad \text{(for any value } \val \text{)} \\
\sem{\letkw \; \var = \val \; \inkw \; \expr} &= \delta_{\expr\subst{\val}{\var}} \\
%
%
\sem{ \fstkw \; \val} & = 
\begin{cases}
	\delta_{\val_1}  & \text{if $\val = (\val_1,\val_2)$ for some values $\val_1,\val_2$} \\
	%
	\delta_{\error}  & \text{otherwise}
\end{cases}
%
\\
%
%
\sem{ \sndkw \; \val} & = 
\begin{cases}
	\delta_{\val_2}  & \text{if $\val = (\val_1,\val_2)$ for some values $\val_1,\val_2$} \\
	%
	\delta_{\error}  & \text{otherwise}
\end{cases}
%
\\
%
\sem{ (\funkw \; \var \; \rightarrow \; \expr) \; \val } &= \delta_{\expr\subst{\val}{\var}}\\
\sem{\error} = \delta_\error \\
\sem{\obsfail} = \delta_\obsfail
\end{align*}
%

\paragraph{Conditionals}
\begin{align*}
\sem{ \ifkw \; \val \; \thenkw \; e_1 \; \elsekw \; e_2 } & = 
\begin{cases}
	\sem{\expr_1}  & \text{if $\val = \true$} \\
	%
	\sem{\expr_2}  & \text{if $\val = \false$} \\
	%
	\delta_\error & \text{otherwise}
\end{cases}
\end{align*}
%

\paragraph{Comparisons}
\begin{align*}
\sem{ v_1 < v_2 } &= \begin{cases}
    \delta_{\text{true}} & \text{if $v_1$ and $v_2$ are float constants and~} v_1 < v_2 \\
    \delta_{\text{false}} & \text{if $v_1$ and $v_2$ are float constants and~} v_1 \geq v_2\\
    \delta_\error & \text{otherwise}
\end{cases} \\
\sem{ v_1 \leq v_2 } &=\begin{cases}
	\delta_{\text{true}} & \text{if $v_1$ and $v_2$ are integer values and~} v_1 < v_2 \\
	\delta_{\text{false}} & \text{if $v_1$ and $v_2$ are integer values and~} v_1 \geq v_2\\
	\delta_\error & \text{otherwise}
\end{cases}
\end{align*}
%

\paragraph{Boolean Operations}
\begin{align*}
%\sem{ \text{true} \logand e } &=  \sem{ e } \\
%\sem{ \text{false} \logand e } &= \delta_{\text{false}} \\
%
\sem{ v \logand e } & = \begin{cases}
	\sem{ e } & \text{if $v=\true$} \\
	\delta_{\text{false}} & \text{if $v=\false$} \\
	\delta_\error & \text{otherwise}
\end{cases} \\ 
%
%=
%\sem{ \text{true} \logor e } &= \delta_{\text{true}} \\
%\sem{ \text{false} \logor e } &= \sem{ e } \\
%
\sem{ v \logor e } & = \begin{cases}
	\delta_\true & \text{if $v=\true$} \\
	\sem{ e } & \text{if $v=\false$} \\
	\delta_\error & \text{otherwise}
\end{cases} \\ 
%
%
\sem{ \text{not}\; v } &= 
 \begin{cases}
	\delta_\false & \text{if $v=\true$} \\
	\delta_\true & \text{if $v=\false$} \\
	\delta_\error & \text{otherwise}
\end{cases} \\ 
 \\
%
%\sem{ \text{not}\; \text{true} } &= \delta_{\text{false}} \\
%\sem{ \text{not}\; \text{false} } &= \delta_{\text{true}}
\end{align*}
%


\subsubsection{Compositional Rules}

For compound expressions, we use monadic bind to compose distributions:

\paragraph{Binary Operations}
\begin{align*}
\sem{ e_1 < e_2 } &= \sem{ e_1 } \gg\!= \lambda v_1. \sem{ v_1 < e_2 } \\
\sem{ v_1 < e_2 } &= \sem{ e_2 } \gg\!= \lambda v_2. \sem{ v_1 < v_2 }
\end{align*}

Similar rules apply for $\leq$, $\logand$, $\logor$, and other binary operations.

\paragraph{Let Binding}
\begin{align*}
\sem{ \letkw \; x = e_1 \; \inkw \; e_2 } &= \sem{ e_1 } \gg\!= \lambda v. \sem{ \letkw \; x = v \; \inkw \; e_2 }
\end{align*}

\paragraph{Conditionals}
\begin{align*}
\sem{ \ifkw \; e_1 \; \thenkw \; e_2 \; \elsekw \; e_3 } &= \sem{ e_1 } \gg\!= \lambda v. \sem{ \ifkw \; v \; \thenkw \; e_2 \; \elsekw \; e_3 }
\end{align*}

\paragraph{Function Application}
\begin{align*}
\sem{ e_1 \; e_2 } &= \sem{ e_1 } \gg\!= \lambda v_1. \sem{ v_1 \; e_2 } \\
\sem{ v_1 \; e_2 } &= \sem{ e_2 } \gg\!= \lambda v_2. \sem{ v_1 \; v_2 }
\end{align*}

\paragraph{Pairs and Projections}
\begin{align*}
\sem{ (e_1, e_2) } &= \sem{ e_1 } \gg\!= \lambda v_1. \sem{ (v_1, e_2) } \\
\sem{ (v_1, e_2) } &= \sem{ e_2 } \gg\!= \lambda v_2. \delta_{(v_1, v_2)} \\
\sem{ \fstkw \; e } &= \sem{ e } \gg\!= \lambda v. \sem{ \fstkw \; v } \\
\sem{ \sndkw \; e } &= \sem{ e } \gg\!= \lambda v. \sem{ \sndkw \; v }
\end{align*}

\paragraph{Sequencing}
\begin{align*}
\sem{ e_1; e_2 } &= \sem{ e_1 } \gg\!= \lambda v_1. \sem{ e_2 }
\end{align*}

\paragraph{Finite Type Operations}
\kevin{why don't we distinguish values and compound expressions here?}
\begin{align*}
\sem{ \finconst{k}{n} } &= \delta_{k_{\#n}} \\
%
\sem{ e_1 \finlt{n} e_2 } &= \sem{ e_1 } \gg\!= \lambda v_1. \sem{ v_1 \finlt{n} e_2 } \\
%
\sem{ k_{1,\#n} \finlt{n} k_{2,\#n} } &= \begin{cases}
    \delta_{\text{true}} & \text{if } k_1 < k_2 \\
    \delta_{\text{false}} & \text{otherwise}
\end{cases} \\
%
\sem{ v_1 \finlt{n} v_1 } &= \begin{cases}
	\delta_{\text{true}} & \text{if $v_1 = k_{1,\#n}$ and $v_2=k_{1,\#n}'$ are finite type values and}~k < k' \\
	\delta_{\text{false}} & \text{if $v_1 = k_{1,\#n}$ and $v_2=k_{1,\#n}'$ are finite type values and}~k \geq k' \\
	\delta_{\error} & \text{otherwise}
\end{cases}
\end{align*}

\subsubsection{Probabilistic Distributions}

For sampling expressions, we map to the corresponding probability distributions:
\kevin{double check if type system should ensure the side conditions}

\begin{align*}
\sem{ \uniform(v_1, v_2) } &= \begin{cases}
\text{Uniform}_{[v_1, v_2)}  & \text{if $v_1$ and $v_2$ are float constants with $v_1 < v_2$} \\
%
\delta_\error & \text{otherwise}
\end{cases}
\\
\sem{ \gaussian(v_\mu, v_\sigma) } &= 
 \begin{cases}
	\mathcal{N}(v_\mu, v_\sigma^2)  & \text{if $v_\mu$ and $v_\sigma$ are float constants with $v_\sigma > 0$} \\
	%
	\delta_\error & \text{otherwise}
\end{cases}
\\
\sem{ \exponential(v_\lambda) } &= 
 \begin{cases}
	\text{Exp}(v_\lambda)   & \text{if $v_\lambda$ is a float constant with $v_\lambda > 0$} \\
	%
	\delta_\error & \text{otherwise}
\end{cases}
\\
\sem{ \betafn(v_\alpha, v_\beta) } &= 
 \begin{cases}
	\text{Beta}(v_\alpha, v_\beta)   & \text{if $v_\alpha$ and $v_\beta$ are float constants with $v_\alpha > 0$ and $v_\beta > 0$} \\
	%
	\delta_\error & \text{otherwise}
\end{cases}
\\
\sem{ \discrete(v_0, \ldots, v_n) } &= %\sum_{i=0}^n p_i \cdot \delta_i
\begin{cases}
	\sum_{i=0}^n v_i \cdot \delta_i & \text{if the $v_i$ a are non-negative float constants with $\sum_i v_i = 1$} \\
	%
	\delta_\error  & \text{otherwise}
\end{cases}
\end{align*}
\kevin{double check discrete}

Note that for continuous distributions, we have an implicit coercion from distributions over reals to distributions over constant expressions. That is, if $D$ is a distribution over $\mathbb{R}$, we treat it as a distribution over expressions by mapping each real $r$ to the constant expression $r$.

\subsubsection{Observations}

Observations condition the distribution:

\begin{align*}
\sem{ \text{observe}\; e } &= \sem{ e } \gg\!= \lambda v. \sem{ \text{observe}\; v } \\
\sem{ \text{observe}\; \text{true} } &= \delta_{()} \\
\sem{ \text{observe}\; \text{false} } &= \bot
\end{align*}

where $\bot$ represents the zero measure (failed observation).

\subsubsection{DistrCase}

For distrcase expressions (which represent explicit discrete distributions in the implementation):

\begin{align*}
\sem{ \text{distrcase}\{(e_0, p_0), \ldots, (e_n, p_n)\} } &= \sum_{i=0}^n p_i \cdot \sem{ e_i }
\end{align*}

\subsubsection{Example}

Consider the expression:
\begin{lstlisting}
let x = uniform(0.0, 1.0) in
if x < 0.5 then 1 else 2
\end{lstlisting}

The probabilistic semantics gives:
\begin{align*}
&\sem{ \text{let } x = \uniform(0.0, 1.0) \text{ in if } x < 0.5 \text{ then } 1 \text{ else } 2 } \\
&= \sem{ \uniform(0.0, 1.0) } \gg\!= \lambda x. \sem{ \text{if } x < 0.5 \text{ then } 1 \text{ else } 2 } \\
&= \text{Uniform}_{[0,1)} \gg\!= \lambda x. \sem{ \text{if } x < 0.5 \text{ then } 1 \text{ else } 2 } \\
&= \text{Uniform}_{[0,1)} \gg\!= \lambda x. \begin{cases}
    \delta_1 & \text{if } x < 0.5 \\
    \delta_2 & \text{if } x \geq 0.5
\end{cases} \\
&= 0.5 \cdot \delta_1 + 0.5 \cdot \delta_2
\end{align*}

This probabilistic semantics forms the foundation for proving that our discretization transformation preserves program behavior.
%
\begin{theorem}
	\label{thm:small-step-well-defined}
	For every $\expr \in \exprs$, $\sem{\expr}$ is a well defined distribution in $\distextexprs$.
\end{theorem}
%
\begin{proof}
	By induction on $\exprs$.
\end{proof}
%
%
\kevin{we will need some relation to nondet semantics. lets see whether we need to add error and obsfail.}
\begin{theorem}
	\label{thm:small-step-well-typed}
	If $\expr : \tau$, then $\sem{\expr}({\error}) = 0$.
\end{theorem}
%
\begin{proof}
	\kevin{probably} By induction on the derivation tree for $\expr : \tau$.
\end{proof}

\subsection{From Small-Step to Big-Step Semantics}
%


\subsection{Measure Space on Expressions}

To make the probabilistic semantics precise, we need to define an appropriate measure space structure on the set of extended expressions. We construct this measure space using the notion of \emph{expression skeletons}.

\subsubsection{Expression Skeletons}

An expression skeleton is an extended expression with ``holes'' where real-valued constants can appear. Formally, we define:

\begin{definition}[Expression Skeleton]
An expression skeleton $s$ is an extended expression where each occurrence of a float constant is replaced by a hole $\square_i$ for some index $i \in \mathbb{N}$. We denote by $\text{Skel}$ the set of all expression skeletons, and by $\text{holes}(s)$ the number of distinct holes in skeleton $s$.
\end{definition}

For example, the expression $\uniform(0.0, 1.0) < 0.5$ has the skeleton $\uniform(\square_1, \square_2) < \square_3$ with three holes.

\subsubsection{Measure Space Construction}

Given a skeleton $s$ with $n = \text{holes}(s)$ holes, we can instantiate it with a vector $\vec{r} = (r_1, \ldots, r_n) \in \mathbb{R}^n$ to produce a concrete expression $s[\vec{r}]$ by replacing each hole $\square_i$ with the real value $r_i$.

The set of all extended expressions can then be represented as:
\[
\extexprs = \bigsqcup_{s \in \text{Skel}} \{s[\vec{r}] \mid \vec{r} \in \mathbb{R}^{\text{holes}(s)}\}
\]

This is a countable disjoint union because:
\begin{enumerate}
    \item The set of skeletons $\text{Skel}$ is countable (expressions have finite syntax trees)
    \item For each skeleton $s$, the set of instantiations forms a copy of $\mathbb{R}^{\text{holes}(s)}$
    \item Different skeletons produce disjoint sets of expressions
\end{enumerate}

\subsubsection{Measurable Sets}

We equip $\extexprs$ with the $\sigma$-algebra generated by sets of the form:
\[
\{s[\vec{r}] \mid \vec{r} \in B\}
\]
where $s$ is a skeleton and $B \subseteq \mathbb{R}^{\text{holes}(s)}$ is a Borel measurable set.

This construction ensures that:
\begin{itemize}
    \item Basic operations like evaluating an expression to a value are measurable
    \item The distributions returned by our probabilistic semantics are well-defined probability measures
    \item We can integrate over expressions when needed for semantic definitions
\end{itemize}

\subsubsection{Distributions Over Expressions}

When we write $\mathcal{D}(\extexprs)$ in our probabilistic semantics, we mean the space of probability measures on $(\extexprs, \mathcal{F})$ where $\mathcal{F}$ is the $\sigma$-algebra described above.

For continuous distributions like $\uniform(a, b)$, the implicit coercion to $\mathcal{D}(\extexprs)$ works as follows:
\begin{enumerate}
    \item The uniform distribution on $[a, b)$ is a measure on $\mathbb{R}$
    \item We lift it to expressions via the skeleton containing a single hole: $s = \square_1$
    \item The resulting distribution on expressions assigns probability to sets of the form $\{r \mid r \in B\}$ for Borel sets $B \subseteq [a, b)$
\end{enumerate}

This measure-theoretic foundation ensures that our probabilistic semantics is mathematically rigorous and that operations like conditioning (via observations) and marginalization are well-defined. 

